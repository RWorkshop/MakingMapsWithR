
\documentclass[Chap4amain.tex]{subfiles}

% Load any packages needed for this document
\begin{document}
%----------------------------------------------------------------------------------------%
%----------------------------------------------------------------------------------------%
\newpage
\section{Statement of the LME model}

Further to a paper published by Laird and Ware in $1982$, a linear mixed effects model is a linear model that combined fixed and random effect terms formulated as follows;

  \begin{displaymath}
      Y_{i} =X_{i}\beta + Z_{i}b_{i} + \epsilon_{i}
  \end{displaymath}
\begin{itemize}

\item $Y_{i}$ is the $n \times 1$ response vector \item $X_{i}$ is the $n \times p$ Model matrix for fixed effects \item $\beta$ is the $p \times 1$ vector of fixed effects coefficients \item $Z_{i}$ is the $n \times q$ Model matrix for random effects \item $b_{i}$ is the $q \times 1$ vector of random effects coefficients,
sometimes denoted as $u_{i}$ \item $\epsilon$ is the $n \times 1$ vector of observation errors
\end{itemize}


\section{The Linear Mixed Effects Model}
The linear mixed effects model is given by
\begin{equation}
Y = X\beta + Zu + \epsilon
\end{equation}


\textbf{Y} is the vector of $n$ observations, with dimension $n
\times 1$. \textbf{b} is a vector of fixed $p$ effects, and has
dimension $p \times 1$. It is composed of coefficients, with the
first element being the population mean.  \textbf{X} is known as
the design `matrix', model matrix for fixed effects, and comprises
$0$s or $1$s, depending on whether the relevant fixed effects have
any effect on the observation is question. \textbf{X} has
dimension $n \times p$. \textbf{e} is the vector of residuals with
dimension $n \times 1$.

The random effects models can be specified similarly. \textbf{Z}
is known as the `model matrix for random effects', and also
comprises $0$s or $1$s. It has dimension $n \times q$. \textbf{u
}is a vector of random $q$ effects, and has dimension $q \times
1$.


% \subsection{Formulation of the Variance Matrix V}
\textbf{V} , the variance matrix of \textbf{Y}, can be expressed
as follows;
\begin{eqnarray}
\textbf{V}= var ( \textbf{Xb} + \textbf{Zu} + \textbf{e})\\
\textbf{V}= var ( \textbf{Xb} ) + var (\textbf{Zu}) +
var(\textbf{e}))
\end{eqnarray}

$\mbox{var}(\textbf{Xb})$ is known to be zero. The variance of the
random effects $\mbox{var}(\textbf{Zu})$ can be written as
$Z\mbox{var}(\textbf{u})Z^{T}$.

By letting var$(u) = G$ (i.e $\textbf{u} ~ N(0,\textbf{G})$), this
becomes $ZGZ^{T}$. This specifies the covariance due to random
effects. The residual covariance matrix $var(e)$ is denoted as
$R$, ($\textbf{e} ~ N(0,\textbf{R})$). Residual are uncorrelated,
hence \textbf{R} is equivalent to $\sigma^{2}$\textbf{I}, where
\textbf{I} is the identity matrix. The variance matrix \textbf{V}
can therefore be written as;

\begin{equation}
\textbf{V}  = ZGZ^{T} + \textbf{R}
\end{equation}

%\subsection{Estimators and Predictors}

The best linear unbiased predictor (BLUP) is used to estimating
random effects, i.e to derive \textbf{u}. The best linear unbiased
estimator (BLUE) is used to estimate the fixed effects,
\textbf{b}. They were formulated in a paper by \cite{Henderson59},
which provides the derivations of both. Inferences about fixed
effects have come to be called `estimates', whereas inferences
about random effects have come be called `predictions`. hence the
naming of BLUP is to reinforce distinction between the two , but
it is essentially the same principal involved in both cases
\citep{Robinson}. The BLUE of \textbf{b}, and the BLUP of
\textbf{u} can be shown to be;

\begin{equation}
\hat{b} = (X^{T}V^{-1}X)^{-1}X^{T}V^{-1}y
\end{equation}
\begin{equation}
\hat{u} = GZ^{T}V^{-1}(y-X\hat{b})
\end{equation}

The practical application of both expressions requires that the variance components be known. An estimate for the variance
components must be derived to  either maximum likelihood (ML) or more commonly restricted maximum likelihood (REML).

Importantly calculations based on the above formulae require the calculation of the inverse of \textbf{V}. In simple examples
$V^{-1}$ is a straightforward calculation, but with higher dimensions it becomes a very complex calculation.




\subsection
The classical model is based on measurements $y_{mi}$ by method $m=1,2$ on item $i = 1,2 \ldots$

\[y_{mi} + \alpha_{m} + \mu_{i} + e_{mi}\]

\[e_{mi} \sim \mathcal{n} (0,\sigma^2_m)\]

Even though the separate variances can not be identified, their sum can be estimated by the empirical variance of the differences.

Like wise the separate $\alpha$ can not be estimated, only theiir difference can be estimated as $\bar{D}$



\newpage
\chapter{LME models for MCS}
\section{Statement of the LME model}

Further to a paper published by Laird and Ware in $1982$, a linear mixed effects model is a linear mdoel that combined fixed and random effect terms formulated as follows;

  \begin{displaymath}
      Y_{i} =X_{i}\beta + Z_{i}b_{i} + \epsilon_{i}
  \end{displaymath}
\begin{itemize}

\item $Y_{i}$ is the $n \times 1$ response vector \item $X_{i}$ is
the $n \times p$ Model matrix for fixed effects \item $\beta$ is
the $p \times 1$ vector of fixed effects coefficients \item
$Z_{i}$ is the $n \times q$ Model matrix for random effects \item
$b_{i}$ is the $q \times 1$ vector of random effects coefficients,
sometimes denoted as $u_{i}$ \item $\epsilon$ is the $n \times 1$
vector of observation errors
\end{itemize}






%-----------------------------------------------------------------------------------------------------%
\newpage

\subsection{Bendix Carstensen's data sets}
\citet{bxc2008}describes the sampling method when discussing of a motivating example.Diabetes patients attending an outpatient clinic in Denmark have their $HbA_{1c}$ levels routinely measured at every visit.Venous and Capillary blood samples were obtained from all patients appearing at the clinic over two days.

Samples were measured on four consecutive days on each machines, hence there are five analysis days.Carstensen notes that every machine was calibrated every day to  the manufacturers guidelines.



%-----------------------------------------------------------------------------------------------------%
\newpage
\section{Hamlett and Lam}
The methodology proposed by \citet{Roy2009} is largely based on \citet{hamlett}, which in turn follows on from \citet{lam}.

%Lam 99
%In many cases, repeated observation are collected from each subject in sequence  and/or longitudinally.

%Hamlett
%Hamlett re-analyses the data of lam et al to generalize their model to cover other settings not covered by the Lam %method.


%-----------------------------------------------------------------------------------------------------%
\newpage
\subsection{Roy's variability tests}
Variability tests proposed by \citet{Roy2009} affords the opportunity to expand upon Carstensen's approach.

The first test allows of the comparison the begin-subject variability of two methods. Similarly, the second test
assesses the within-subject variability of two methods. A third test is a test that compares the overall variability of the two methods.

The tests are implemented by fitting a specific LME model, and three variations thereof, to the data. These three variant models introduce equality constraints that act null hypothesis cases.

Other important aspects of the method comparison study are consequent. The limits of agreement are computed using the results of the first model.

\section{Carstensen's Mixed Models}

\citet{BXC2004} proposes linear mixed effects models for deriving
conversion calculations similar to Deming's regression, and for
estimating variance components for measurements by different
methods. The following model ( in the authors own notation) is
formulated as follows, where $y_{mir}$ is the $r$th replicate
measurement on subject $i$ with method $m$.

\begin{equation}
y_{mir}  = \alpha_{m} + \beta_{m}\mu_{i} + c_{mi} + e_{mir} \qquad
( e_{mi} \sim N(0,\sigma^{2}_{m}), c_{mi} \sim N(0,\tau^{2}_{m}))
\end{equation}
The intercept term $\alpha$ and the $\beta_{m}\mu_{i}$ term follow
from \citet{DunnSEME}, expressing constant and proportional bias
respectively , in the presence of a real value $\mu_{i}.$
 $c_{mi}$ is a interaction term to account for replicate, and
 $e_{mir}$ is the residual associated with each observation.
Since variances are specific to each method, this model can be
fitted separately for each method.

The above formulation doesn't require the data set to be balanced.
However, it does require a sufficient large number of replicates
and measurements to overcome the problem of identifiability. The
import of which is that more than two methods of measurement may
be required to carry out the analysis. There is also the
assumptions that mobservations of measurements by particular
methods are exchangeable within subjects. (Exchangeability means
that future samples from a population behaves like earlier
samples).

%\citet{BXC2004} describes the above model as a `functional model',
%similar to models described by \citet{Kimura}, but without any
%assumptions on variance ratios. A functional model is . An
%alternative to functional models is structural modelling

\citet{BXC2004} uses the above formula to predict observations for
a specific individual $i$ by method $m$;

\begin{equation}BLUP_{mir} = \hat{\alpha_{m}} + \hat{\beta_{m}}\mu_{i} +
c_{mi} \end{equation}. Under the assumption that the $\mu$s are
the true item values, this would be sufficient to estimate
parameters. When that assumption doesn't hold, regression techniques (known as updating techniques)
can be used additionally to determine the estimates.
The assumption of exchangeability can be unrealistic in certain situations.
\citet{BXC2004} provides an amended formulation which includes an extra interaction
term ($d_{mr} d_{mr} \sim N(0,\omega^{2}_{m}$)to account for this.

\citet{BXC2008} sets out a methodology of computing the limits of
agreement based upon variance component estimates derived using
linear mixed effects models. Measures of repeatability, a
characteristic of individual methods of measurements, are also
derived using this method.




\citet{pkcng} generalize this approach to account for situations
where the distributions are not identical, which is commonly the
case. The TDI is not consistent and may not preserve its
asymptotic nominal level, and that the coverage probability
approach of \citet{lin2002} is overly conservative for moderate
sample sizes. This methodology proposed by \citet{pkcng} is a
regression based approach that models the mean and the variance of
differences as functions of observed values of the average of the
paired measurements.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%5

Maximum likelihood estimation is used to estimate the parameters.
The REML estimation is not considered since it does not lead to a
joint distribution of the estimates of fixed effects and random
effects parameters, upon which the assessment of agreement is
based.

\section{Random Effects and MCS}
The methodology comprises two calculations. The second calculation
is for the standard deviation of means Before the modified Bland
and Altman method can be applied for repeated measurement data, a
check of the assumption that the variance of the repeated
measurements for each subject by each method is independent of the
mean of the repeated measures. This can be done by plotting the
within-subject standard deviation against the mean of each subject
by each method. Mean Square deviation measures the total deviation
of a


\subsection{Random coefficient growth curve model} (Chincilli
1996) Random coefficient growth curve model, a special type of
mixed model have been proposed a single measure of agreement for
repeated measurements.
\begin{equation}
\textbf{d}= \textbf{Xb} + \textbf{Zu} + \textbf{e}
\end{equation}
The distributional asummptions also require \textbf{d} to
\textbf{N}

%------------------------------------------------------------------
\newpage
\section{Other Approaches}

\subsection{Random coefficient growth curve model} (Chincilli
1996) Random coefficient growth curve model, a special type of
mixed model have been proposed  a single measure of agreement for
repeated measurements.
\subsection{Marginal Modelling}
(Diggle 2002) proposes the use of marginal models as an
alternative to mixed models.m Marginal models are appropriate when
interences about the mean response are of specific interest.
\section{KP}
Most residual covariance structures are design for one
within-subject factor. However two or more may be present. For
such cases,an approppriate approach would be the residual
covariance structure using Kronecker product of the underlying
within-subject factor specific covariances structure.

\section{LME}
Consistent with the conventions of mixed models, \citet{pkc}
formulates the measurement $y_{ij} $from method $i$ on individual
$j$ as follows;
\begin{equation}
y_{ij} =P_{ij}\theta + W_{ij}v_{i} + X_{ij}b_{j} + Z_{ij}u_{j} +
\epsilon_{ij},     (j=1,2, i=1,2....n)
\end{equation}
The design matrix $P_{ij}$ , with its associated column vector
$\theta$, specifies the fixed effects common to both methods. The
fixed effect specific to the $j$th method is articulated by the
design matrix $W_{ij}$ and its column vector $v_{i}$. The random
effects common to both methods is specified in the design matrix
$X_{ij}$, with vector $b_{j}$ whereas the random effects specific
to the $i$th subject by the $j$th method is expressed by $Z_{ij}$,
and vector $u_{j}$. Noticeably this notation is not consistent
with that described previously.  The design matrices are specified
so as to includes a fixed intercept for each method, and a random
intercept for each individual. Additional assumptions must also be
specified;
\begin{equation}
v_{ij} \sim N(0,\Sigma),
\end{equation}
These vectors are assumed to be independent for different $i$s,
and are also mutually independent. All Covariance matrices are
positive definite.  In the above model effects can be classed as
those common to both methods, and those that vary with method.
When considering differences, the effects common to both
effectively cancel each other out. The differences of each pair of
measurements can be specified as following;
\begin{equation}
d_{ij} = X_{ij}b_{j} + Z_{ij}u_{j} + \epsilon_{ij},     (j=1,2,
i=1,2....n)
\end{equation}
This formulation has seperate distributional assumption from the
model stated previously.

This agreement covariate $x$ is the key step in how this
methodology assesses agreement.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%5



%-----------------------------------------------------------------------------------------------------%
\newpage
\bibliography{DB-txfrbib}
\end{document}